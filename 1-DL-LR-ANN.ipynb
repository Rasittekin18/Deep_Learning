{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d49ab8b-5b25-4b12-b890-7bc992d1ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign language digits dataset \n",
    "# colorspace : grayscale , file format : npy , number of participant students : 218 , number of samples per student : 10\n",
    "# X.npy ve Y.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5043f4c-102b-4957-9210-09f104bfc5cd",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b43ba7-e736-4153-86c1-be35db17307b",
   "metadata": {},
   "source": [
    "* **Deep learning:** One of the machine learning technique that learns features directly from data. \n",
    "* **Why deep learning:** When the amounth of data is increased, machine learning techniques are insufficient in terms of performance and deep learning gives better performance like accuracy.\n",
    "![resim](1.jpg)\n",
    "* **What is amounth of big:** It is hard to answer but intuitively 1 million sample is enough to say \"big amounth of data\"\n",
    "* **Usage fields of deep learning:** Speech recognition ( zaman serileri), image classification, natural language procession (nlp) or recommendation systems\n",
    "* **What is difference of deep learning from machine learning:** \n",
    "    * Machine learning covers deep learning. \n",
    "    * Features are given machine learning manually.\n",
    "    * On the other hand, deep learning learns features directly from data.\n",
    "![resim](2.jpg)\n",
    "\n",
    "<br>Lets look at our data.\n",
    "* Deep learning de datadan diretk öğrenme var. Feature çıkarma falan yok.\n",
    "* Belirli bir data büyüklğüne kadar aynı performansı verirler ama data çok büyüyünce ml teknikleri yetersiz kalır. accuracy düşük çıkar.\n",
    "* bizim datamız 2800 verilik ancak bunda da deep learning kullanabiliriz. data küçük diye kullanılmaz diye bir şey yoktur.\n",
    "* deep learning ml'in alt kümesidir.\n",
    "* ml  de featureları vermek zorundayız deep learning de vermek zorunda değiliz.\n",
    "* mesela bir köpek kedi fotoğrafını sinir ağına sokunca ömenmli özellikleri extract ediyo zaten deep learning\n",
    "* datadan direkt kendi öğrenir\n",
    "* ml de ise önemli özellikleri kendim classification algoritmama input olarak veririm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f553c-3f62-4429-8b8e-6ec3456c1c86",
   "metadata": {},
   "source": [
    "# Overview the Data Set\n",
    "* We will use \"sign language digits data set\" for this tutorial.\n",
    "* In this data there are 2062 sign language digits images.\n",
    "* As you know digits are from 0 to 9. Therefore there are 10 unique sign.\n",
    "* At the beginning of tutorial we will use only sign 0 and 1 for simplicity.  ( kolay olsun diye 0 ve 1 i class edicez)\n",
    "* In data, sign zero is between indexes 204 and 408. Number of zero sign is 205. ( her bir sınıftan 205 tane simple olucak)\n",
    "* Also sign one is between indexes 822 and 1027. Number of one sign is 206. Therefore, we will use 205 samples from each classes(labels).\n",
    "* Note: Actually 205 sample is very very very little for deep learning. But this is tutorial so it does not matter so much. \n",
    "* Lets prepare our X and Y arrays. X is image array (zero and one signs) and Y is label array (0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8584a1-a512-4f1b-9c7b-53c19e98351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc4c960-3067-42a0-91aa-e29d8d6e91ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 63.5, 63.5, -0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data set\n",
    "x_l = np.load('X.npy')\n",
    "Y_l = np.load('Y.npy')\n",
    "img_size = 64\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_l[260].reshape(img_size, img_size))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_l[900].reshape(img_size, img_size))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68bd534-9401-4f45-8da9-0e7fc2d8cff9",
   "metadata": {},
   "source": [
    "* In order to create image array, I concatenate zero sign and one sign arrays\n",
    "* Then I create label array 0 for zero sign images and 1 for one sign images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "522af52f-cff3-4c82-914e-0e5d78c3a39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (410, 64, 64)\n",
      "Y shape:  (410, 1)\n"
     ]
    }
   ],
   "source": [
    "# Join a sequence of arrays along an row axis.\n",
    "# x array oluşturucaz 0 ve 1lerden \n",
    "X = np.concatenate((x_l[204:409], x_l[822:1027] ), axis=0) # from 0 to 204 is zero sign and from 205 to 410 is one sign \n",
    "z = np.zeros(205)\n",
    "o = np.ones(205)\n",
    "Y = np.concatenate((z, o), axis=0).reshape(X.shape[0],1) # labellardan 0 ve 1 leride alıp concat yapıyorum.\n",
    "print(\"X shape: \" , X.shape)\n",
    "print(\"Y shape: \" , Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f63887-5fc5-45a3-8621-76577869a71a",
   "metadata": {},
   "source": [
    "* 64*64 bir resim 4096 tane sayı var \n",
    "* The shape of the X is (410, 64, 64)\n",
    "    * 410 means that we have 410 images (zero and one signs)\n",
    "    * 64 means that our image size is 64x64 (64x64 pixels)\n",
    "* The shape of the Y is (410,1)\n",
    "    *  410 means that we have 410 labels (0 and 1) \n",
    "* Lets split X and Y into train and test sets.\n",
    "    * test_size = percentage of test size. test = 15% and train = 75%\n",
    "    * random_state = use same seed while randomizing. It means that if we call train_test_split repeatedly, it always creates same train and test distribution because we have same random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "182c79bf-76fa-4e3e-8878-f3c6e4d9e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then lets create x_train, y_train, x_test, y_test arrays\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "number_of_train = X_train.shape[0]\n",
    "number_of_test = X_test.shape[0] # x 3 boyutlu y 2 boyutlu x'i de 2 boyutlu hale getirmek lazım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "920eeb8e-1872-40ec-8f6d-619d7771901b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048bb21a-6a3f-4f9b-bcf1-e63aa104470b",
   "metadata": {},
   "source": [
    "* Now we have 3 dimensional input array (X) so we need to make it flatten (2D) in order to use as input for our first deep learning model.\n",
    "* Our label array (Y) is already flatten(2D) so we leave it like that.\n",
    "* Lets flatten X array(images array).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21861606-11e0-40ff-bfae-37921b9bd017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train flatten (348, 4096)\n",
      "X test flatten (62, 4096)\n"
     ]
    }
   ],
   "source": [
    "X_train_flatten = X_train.reshape(number_of_train,X_train.shape[1]*X_train.shape[2]) # datamı reshape yapıp flatten yani 2 boyutlu hale getiriyorum\n",
    "X_test_flatten = X_test .reshape(number_of_test,X_test.shape[1]*X_test.shape[2])\n",
    "print(\"X train flatten\",X_train_flatten.shape)\n",
    "print(\"X test flatten\",X_test_flatten.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa710c2-cd6a-48f5-86f7-7f93e5f08b0f",
   "metadata": {},
   "source": [
    "* As you can see, we have 348 images and each image has 4096 pixels in image train array.\n",
    "* Also, we have 62 images and each image has 4096 pixels in image test array.\n",
    "* Then lets take transpose. You can say that WHYY, actually there is no technical answer. I just write the code(code that you will see oncoming parts) according to it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fcfb3e3-34bc-443a-bfff-0afa00bfb24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (4096, 348)\n",
      "x test:  (4096, 62)\n",
      "y train:  (1, 348)\n",
      "y test:  (1, 62)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train_flatten.T\n",
    "x_test = X_test_flatten.T\n",
    "y_train = Y_train.T\n",
    "y_test = Y_test.T\n",
    "print(\"x train: \",x_train.shape)\n",
    "print(\"x test: \",x_test.shape)\n",
    "print(\"y train: \",y_train.shape)\n",
    "print(\"y test: \",y_test.shape)\n",
    "# çarpım yapabilmek için transpoze alıyoruz. eğer ki burda almazsan bu sefer de çarpım yapacağım weightlerin transopezunu alman gerecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "564d2c5f-3c70-404a-a419-90c246174b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5*6  3*6.T ----> 5*6 6*3 --- 5*3\n",
    "# ya da  3*6  5*6.T ----> 3*6  6*5 ---- 3*5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3e3a5-faca-4abc-b069-73a1b3c18926",
   "metadata": {},
   "source": [
    "<font color='purple'>\n",
    "What we did up to this point:\n",
    "* Choose our labels (classes) that are sign zero and sign one\n",
    "* Create and flatten train and test sets\n",
    "* Our final inputs(images) and outputs(labels or classes) looks like this:\n",
    "    \n",
    "![resim](3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e6a1c-7ab6-49d7-8069-dd6366b957de",
   "metadata": {},
   "source": [
    "* 4096 pixel 348 resim \n",
    "* resmi  ifade etmek için array kullanıyorum\n",
    "* 4096*1 'lik array\n",
    "* 1,1,1\n",
    "* 2,2,2\n",
    "* 3,3,3 bu 3 boyutluyu\n",
    "* 1\n",
    "* 1\n",
    "* 1\n",
    "* 2\n",
    "* 2\n",
    "* 2\n",
    "* 3\n",
    "* 3\n",
    "* 3 şeklinde 3'e 3 luk matrısı 9'a 1 lık hale getirdik. Resimde de 64*64'u  4096 1 olarak 3 boyuttan 2 boyuta düşmüş olduk\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef0128-4683-47bb-a91b-29ca2ba977cb",
   "metadata": {},
   "source": [
    "\n",
    "# Logistic Regression\n",
    "* When we talk about binary classification( 0 and 1 outputs) what comes to mind first is logistic regression.\n",
    "* However, in deep learning tutorial what to do with logistic regression there??\n",
    "* The answer is that  logistic regression is actually a very simple neural network. \n",
    "* By the way neural network and deep learning are same thing. When we will come artificial neural network, I will explain detailed the terms like \"deep\".\n",
    "* In order to understand logistic regression (simple deep learning) lets first learn computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7637eb-167b-45fe-b804-c1d751f07e21",
   "metadata": {},
   "source": [
    "\n",
    "##  Computation Graph\n",
    "* Computation graphs are a nice way to think about mathematical expressions.\n",
    "* It is like visualization of  mathematical expressions.\n",
    "* For example we have $$c = \\sqrt{a^2 + b^2}$$\n",
    "* It's computational graph is this. As you can see we express math with graph.\n",
    "\n",
    "\n",
    "![resim](4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052dfa44-e9d1-4d70-8b9c-b61bccc0bfda",
   "metadata": {},
   "source": [
    "* Now lets look at computation graph of logistic regression\n",
    "![resim](5.jpg)\n",
    "    * Parameters are weight and bias.\n",
    "    * Weights: coefficients of each pixels\n",
    "    * Bias: intercept\n",
    "    * z = (w.t)x + b  => z equals to (transpose of weights times input x) + bias \n",
    "    * In an other saying => z = b + px1*w1 + px2*w2 + ... + px4096*w4096\n",
    "    * y_head = sigmoid(z)\n",
    "    * Sigmoid function makes z between zero and one so that is probability. You can see sigmoid function in computation graph.\n",
    "* Why we use sigmoid function?\n",
    "    * It gives probabilistic result\n",
    "    * It is derivative so we can use it in gradient descent algorithm (we will see as soon.)\n",
    "* Lets make example:\n",
    "    * Lets say we find z = 4 and put z into sigmoid function. The result(y_head) is almost 0.9. It means that our classification result is 1 with 90% probability.\n",
    "* Now lets start with from beginning and examine each component of computation graph more detailed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841de3a0-fd29-4c61-a53b-f44737051f62",
   "metadata": {},
   "source": [
    "\n",
    "## Initializing parameters\n",
    "* As you know input is our images that has 4096 pixels(each image in x_train).\n",
    "* Each pixels have own weights.\n",
    "* The first step is multiplying each pixels with their own weights.\n",
    "* The question is that what is the initial value of weights?\n",
    "    * There are some techniques that I will explain at artificial neural network but for this time initial weights are 0.01.\n",
    "    * Okey, weights are 0.01 but what is the weight array shape? As you understand from computation graph of logistic regression, it is (4096,1)\n",
    "    * Also initial bias is 0.\n",
    "* Lets write some code. In order to use at coming topics like artificial neural network (ANN), I make definition(method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32105adc-4e4d-4f19-81be-6026d258f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short description and example of definition (def) , python da metot yazma yöntemine baktık\n",
    "def dummy(parameter):\n",
    "    dummy_parameter = parameter + 5\n",
    "    return dummy_parameter\n",
    "result = dummy(3)     # result = 8\n",
    "\n",
    "# lets initialize parameters\n",
    "# So what we need is dimension 4096 that is number of pixels as a parameter for our initialize method(def)\n",
    "def initialize_weights_and_bias(dimension): # dimension : bir resmin boyutu\n",
    "    w = np.full((dimension,1),0.01) # 4096,1 'lik matris oluşturur ve bu matrisin içine 0.01 değerlerini atar.\n",
    "    b = 0.0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f770319c-70a7-41be-8e85-aafa075e681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w,b = initialize_weights_and_bias(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c85e613-d435-42d1-9796-e34aea57ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1027e7e6-80ad-4630-b79b-2d1aeaa4a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f72dffb3-9a1c-412f-9b2c-85795fadbad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c73f59-85c1-4895-9a36-b0cafedd74d8",
   "metadata": {},
   "source": [
    "\n",
    "## Forward Propagation\n",
    "* The all steps from pixels to cost is called forward propagation\n",
    "    * z = (w.T)x + b => in this equation we know x that is pixel array, we know w (weights) and b (bias) so the rest is calculation. (T is transpose)\n",
    "    * Then we put z into sigmoid function that returns y_head(probability). When your mind is confused go and look at computation graph. Also equation of sigmoid function is in computation graph.\n",
    "    * Then we calculate loss(error) function. \n",
    "    * Cost function is summation of all loss(error).\n",
    "    * Lets start with z and the write sigmoid definition(method) that takes z as input parameter and returns y_head(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecf72a0b-0f22-488b-92cb-b7540ffb41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of z\n",
    "#z = np.dot(w.T,x_train)+b\n",
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head\n",
    "#y_head = sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8c1d361-2ceb-4ab7-80f3-e129d46e264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_head = sigmoid(10)  #  , 0  da  0.5\n",
    "#y_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d10b65-7099-41ed-8daa-21378f504b44",
   "metadata": {},
   "source": [
    "* As we write sigmoid method and calculate y_head. Lets learn what is loss(error) function\n",
    "* Lets make example, I put one image as input then multiply it with their weights and add bias term so I find z. Then put z into sigmoid method so I find y_head. Up to this point we know what we did. Then e.g y_head became 0.9 that is bigger than 0.5 so our prediction is image is sign one image. Okey every thing looks like fine. But, is our prediction is correct and how do we check whether it is correct or not? The answer is with loss(error) function:\n",
    "    * Mathematical expression of log loss(error) function is that: \n",
    "    ![resim](6.jpg)\n",
    "    * It says that if you make wrong prediction, loss(error) becomes big.\n",
    "        * Example: our real image is sign one and its label is 1 (y = 1), then we make prediction y_head = 1. When we put y and y_head into loss(error) equation the result is 0. We make correct prediction therefore our loss is 0. However, if we make wrong prediction like y_head = 0, loss(error) is infinity.\n",
    "* After that, the cost function is summation of loss function. Each image creates loss function. Cost function is summation of loss functions that is created by each input image.\n",
    "* Lets implement forward propagation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9632add-ad5c-48ae-a97a-40d63e70c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation steps:\n",
    "# find z = w.T*x+b\n",
    "# y_head = sigmoid(z)\n",
    "# loss(error) = loss(y,y_head)\n",
    "# cost = sum(loss)\n",
    "def forward_propagation(w,b,x_train,y_train):\n",
    "    z = np.dot(w.T,x_train) + b\n",
    "    y_head = sigmoid(z) # probabilistic 0-1\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    cost = (np.sum(loss))/x_train.shape[1]      # x_train.shape[1]  is for scaling\n",
    "    return cost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f448c9-f454-4f53-9fb3-88f286be8d4f",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> <br>\n",
    "##  Optimization Algorithm with Gradient Descent\n",
    "* Well, now we know what is our cost that is error.\n",
    "* Therefore, we need to decrease cost because as we know if cost is high it means that we make wrong prediction.\n",
    "* Lets think first step, every thing starts with initializing weights and bias. Therefore cost is dependent with them.\n",
    "* In order to decrease cost, we need to update weights and bias.\n",
    "* In other words, our model needs to learn the parameters weights and bias that minimize cost function. This technique is called gradient descent.\n",
    "* Lets make an example:\n",
    "    * We have w = 5 and bias = 0 (so ignore bias for now). Then we make forward propagation and our cost function is 1.5.\n",
    "    * It looks like this. (red lines)\n",
    "    ![resim](7.jpg)\n",
    "    * As you can see from graph, we are not at minimum point of cost function. Therefore we need to go through minimum cost. Okey, lets update weight. ( the symbol := is updating)\n",
    "    * w := w - step. The question is what is this step? Step is slope1. Okey, it looks remarkable. In order to find minimum point, we can use slope1. Then lets say slope1 = 3 and update our weight. w := w - slope1 => w = 2.\n",
    "    * Now, our weight w is 2. As you remember, we need to find cost function with forward propagation again. \n",
    "    * Lets say according to forward propagation with w = 2, cost function is 0.4. Hmm, we are at right way because our cost function is decrease. We have new value for cost function that is cost = 0.4. Is that enough? Actually I do not know lets try one more step.\n",
    "    * Slope2 = 0.7 and w = 2. Lets update weight w : = w - step(slope2) => w = 1.3 that is new weight. So lets find new cost.\n",
    "    * Make one more forward propagation with w = 1.3 and our cost = 0.3. Okey, our cost even decreased, it looks like fine but is it enough or do we need to make one more step? The answer is again I do not know, lets try.\n",
    "    * Slope3 = 0.01 and w = 1.3. Updating weight w := w - step(slope3) => w = 1.29 ~ 1.3. So weight does not change because we find minimum point of cost function. \n",
    "    * Everything looks like good but how we find slope? If you remember from high school or university, in order to find slope of function(cost function) at given point(at given weight) we take derivative of function at given point. Also you can ask that okey well we find slope but how it knows where it go. You can say that it can go more higher cost values instead of going minimum point. The asnwer is that slope(derivative) gives both step and direction of step. Therefore do not worry :)\n",
    "    * Update equation is this. It says that there is a cost function(takes weight and bias). Take derivative of cost function according to weight and bias. Then multiply it with  α learning rate. Then update weight. (In order to explain I ignore bias but these all steps will be applied for bias)\n",
    "    ![resim](8.jpg)\n",
    "    * Now, I am sure you are asking what is learning rate that I mentioned never. It is very simple term that determines learning rate. Hovewer there is tradeoff between learning fast and never learning. For example you are at Paris(current cost) and want to go Madrid(minimum cost). If your speed(learning rate) is small, you can go Madrid very slowly and it takes too long time. On ther other hand, if your speed(learning rate) is big, you can go very fast but maybe you make crash and never go to Madrid. Therefore, we need to choose wisely our speed(learning rate).\n",
    "    * Learning rate is also called hyperparameter that need to be chosen and tuned. I will explain it more detailed in artificial neural network with other hyperparameters. For now just say learning rate is 1 for our previous example.\n",
    "  \n",
    "* I think now you understand the logic behind forward propagation(from weights and bias to cost) and backward propagation(from cost to weights and bias to update them). Also you learn gradient descent. Before implementing the code you need to learn one more thing that is how we take derivative of cost function according to weights and bias. It is not related with python or coding. It is pure mathematic. There are two option first one is to google how to take derivative of log loss function and second one is even to google what is derivative of log loss function :) I choose second one because I cannot explain math without talking :) \n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}x(  y_head - y)^T$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (y_head-y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb0690c4-5911-4142-b70b-6686e50757c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In backward propagation we will use y_head that found in forward progation\n",
    "# Therefore instead of writing backward propagation method, lets combine forward propagation and backward propagation\n",
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    # forward propagation\n",
    "    z = np.dot(w.T,x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    cost = (np.sum(loss))/x_train.shape[1]      # x_train.shape[1]  is for scaling\n",
    "    # backward propagation\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]                 # x_train.shape[1]  is for scaling\n",
    "    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2490e44-9e9a-4a19-ab0c-6c98c53b959e",
   "metadata": {},
   "source": [
    "* Up to this point we learn \n",
    "    * Initializing parameters (implemented)\n",
    "    * Finding cost with forward propagation and cost function (implemented)\n",
    "    * Updating(learning) parameters (weight and bias). Now lets implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7022728-63ca-4661-8630-019c0ccaec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating(learning) parameters\n",
    "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    # updating(learning) parameters is number_of_iterarion times\n",
    "    for i in range(number_of_iterarion):\n",
    "        # make forward and backward propagation and find cost and gradients\n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n",
    "        cost_list.append(cost)\n",
    "        # lets update\n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    # we update(learn) parameters weights and bias\n",
    "    parameters = {\"weight\": w,\"bias\": b}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list\n",
    "#parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate = 0.009,number_of_iterarion = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0367d-1acf-4874-8bc7-a5ffeb010342",
   "metadata": {},
   "source": [
    "* Woow, I get tired :) Up to this point we learn our parameters. It means we fit the data. \n",
    "* In order to predict we have parameters. Therefore, lets predict.\n",
    "* In prediction step we have x_test as a input and while using it, we make forward prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8fda802-81a6-4259-9397-b08cc9f8c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " # prediction\n",
    "def predict(w,b,x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    z = sigmoid(np.dot(w.T,x_test)+b)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))  # y head olmalı  , 0'lardan oluşan bir array oluşturdum yer açtım yani yoksa kod çok yavaş çalışır \n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction\n",
    "# predict(parameters[\"weight\"],parameters[\"bias\"],x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940d5b5b-6293-408d-bbb6-6d16e42e10d7",
   "metadata": {},
   "source": [
    "* We make prediction.\n",
    "* Now lets put them all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9acba9bd-7a5e-4bdc-9407-8437744608cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 14.014222\n",
      "Cost after iteration 10: 2.544689\n",
      "Cost after iteration 20: 2.577950\n",
      "Cost after iteration 30: 2.397999\n",
      "Cost after iteration 40: 2.185019\n",
      "Cost after iteration 50: 1.968348\n",
      "Cost after iteration 60: 1.754195\n",
      "Cost after iteration 70: 1.535079\n",
      "Cost after iteration 80: 1.297567\n",
      "Cost after iteration 90: 1.031919\n",
      "Cost after iteration 100: 0.737019\n",
      "Cost after iteration 110: 0.441355\n",
      "Cost after iteration 120: 0.252278\n",
      "Cost after iteration 130: 0.205168\n",
      "Cost after iteration 140: 0.196168\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 92.816091954023 %\n",
      "test accuracy: 93.54838709677419 %\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n",
    "    # initialize\n",
    "    dimension =  x_train.shape[0]  # that is 4096\n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "    # do not change learning rate\n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "    y_prediction_train = predict(parameters[\"weight\"],parameters[\"bias\"],x_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 0.01, num_iterations = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd203fa-e7cf-4b33-9c87-c85ae055dbbe",
   "metadata": {},
   "source": [
    "* We learn logic behind simple neural network(logistic regression) and how to implement it.\n",
    "* Now that we have learned logic, we can use sklearn library which is easier than implementing all steps with hand for logistic regression.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b8b97-ce4e-40fd-a771-dcabbbf70e66",
   "metadata": {},
   "source": [
    "\n",
    "## Logistic Regression with Sklearn\n",
    "* In sklearn library, there is a logistic regression method that ease implementing logistic regression.\n",
    "* I am not going to explain each parameter of logistic regression in sklear but if you want you can read from there http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "* The accuracies are different from what we find. Because logistic regression method use a lot of different feature that we do not use like different optimization parameters or regularization.\n",
    "* Lets make conclusion for logistic regression and continue with artificial neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33dd79eb-4441-40a9-981e-dfacedd3867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.967741935483871 \n",
      "train accuracy: 1.0 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(random_state = 42,max_iter= 150)\n",
    "print(\"test accuracy: {} \".format(logreg.fit(x_train.T, y_train.T).score(x_test.T, y_test.T)))\n",
    "print(\"train accuracy: {} \".format(logreg.fit(x_train.T, y_train.T).score(x_train.T, y_train.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b994387-aeb8-4158-a592-f2c7ebf43af7",
   "metadata": {},
   "source": [
    "\n",
    "# Artificial Neural Network (ANN)\n",
    "* It is also called deep neural network or deep learning.\n",
    "* **What is neural network:** It is basically taking logistic regression and repeating it at least 2 times.\n",
    "* In logistic regression, there are input and output layers. However, in neural network, there is at least one hidden layer between input and output layer.\n",
    "* **What is deep, in order to say \"deep\" how many layer do I need to have:** When I ask this question to my teacher, he said that \"\"Deep\" is a relative term; it of course refers to the \"depth\" of a network, meaning how many hidden layers it has. \"How deep is your swimming pool?\" could be 12 feet or it might be two feet; nevertheless, it still has a depth--it has the quality of \"deepness\". 32 years ago, I used two or three hidden layers. That was the limit for the specialized hardware of the day. Just a few years ago, 20 layers was considered pretty deep. In October, Andrew Ng mentioned 152 layers was (one of?) the biggest commercial networks he knew of. Last week, I talked to someone at a big, famous company who said he was using \"thousands\". So I prefer to just stick with \"How deep?\"\"\n",
    "* **Why it is called hidden:** Because hidden layer does not see inputs(training set)\n",
    "* For example you have input, one hidden and output layers. When someone ask you \"hey my friend how many layers do your neural network have?\" The answer is \"I have 2 layer neural network\". Because while computing layer number input layer is ignored.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "* ANN,CNN,RNN deep learningtir.\n",
    "* Lojistik regresyonu alıp iki kere tekrar etmeye yarar.\n",
    "* en az 2 kez -- 2 layer, 1 kez 1 layer\n",
    "* hidden layer ne kadar hidden içerirse neural networkume deep diyebilirim\n",
    "* deep kelimesi kişiden kişiye zamana göre değişen kavramdır. 30 yıl önce 2-3 katman deep iken şimdi 152 katman deep mesela. Ya da bilgisayar kötüyse 6-7 katman deep gibi .\n",
    "* neural network demek daha mantıklıdır.\n",
    "* hidden layer yani gizli tabaka denme sebebi input görmüyorlar\n",
    "* input layerı layer saymada saymazsın yukarda 2 layer var deriz mesela\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* Lets see 2 layer neural network: \n",
    "![resim](9.jpg)\n",
    "* Step by step we will learn this image.\n",
    "    * As you can see there is one hidden layer between input and output layers. And this hidden layer has 3 nodes. If yoube curious why I choose number of node 3, the answer is there is no reason, I only choose :). Number of node is hyperparameter like learning rate. Therefore we will see hyperparameters at the end of artificial neural network.\n",
    "    * Input and output layers do not change. They are same like logistic regression.\n",
    "    * In image, there is a tanh function that is unknown for you. It is a activation function like sigmoid function. Tanh activation function is better than sigmoid for hidden units bacause mean of its output is closer to zero so it centers the data better for the next layer. Also tanh activation function increase non linearity that cause our model learning better.\n",
    "    * As you can see with purple color there are two parts. Both parts are like logistic regression. The only difference is activation function, inputs and outputs.\n",
    "        * In logistic regression: input => output\n",
    "        * In 2 layer neural network: input => hidden layer => output. You can think that hidden layer is output of part 1 and input of part 2.\n",
    "* Thats all. We will follow the same path like logistic regression for 2 layer neural network.\n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4bf54-b3b7-439f-9450-f7fbef368185",
   "metadata": {},
   "source": [
    "* İnputta 4096 adet node var.\n",
    "* node sayısı ve hidden sayısı hyperparameter\n",
    "* sigmoid 0-1 arasında sıkıştırır, tanh ise -1 1 arasında sıkıştırır.\n",
    "* tanh kullanılma sebeplerinden birisi ortalaması 0'a daha yakındır, datayı daha iyi merkezde tutuyorum anlamındadır.\n",
    "* hidden layer da relu,tanh fonksiyonları falan kullanılır. Sigmoid kullanılmaz.\n",
    "* tanh kullanılma sebeplerinden birisi de datadan öğrenilen modeldeki nonlineerliği artırmak, karmaşıklığı artırıyoruz yani\n",
    "* part 1 ve part 2 kısımlarına bakıldığında art arda iki tane lojistik regresyon yapıldığı görülür.\n",
    "* Update edilecekler : w1,w2,b1,b2\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57e17c1-970c-4ecc-bf29-47617613ab3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7320e9d6-ad4d-47d5-9f2e-0582677b1065",
   "metadata": {},
   "source": [
    "\n",
    "## 2-Layer Neural Network\n",
    "* Size of layers and initializing parameters weights and bias\n",
    "* Forward propagation\n",
    "* Loss function and Cost function\n",
    "* Backward propagation\n",
    "* Update Parameters\n",
    "* Prediction with learnt parameters weight and bias\n",
    "* Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee38cb0-e25c-4716-84e3-eebd3634347a",
   "metadata": {},
   "source": [
    "\n",
    "## Size of layers and initializing parameters weights and bias\n",
    "* For x_train that has 348 sample $x^{(348)}$:\n",
    "$$z^{[1] (348)} =  W^{[1]} x^{(348)} + b^{[1] (348)}$$ \n",
    "$$a^{[1] (348)} = \\tanh(z^{[1] (348)})$$\n",
    "$$z^{[2] (348)} = W^{[2]} a^{[1] (348)} + b^{[2] (348)}$$\n",
    "$$\\hat{y}^{(348)} = a^{[2] (348)} = \\sigma(z^{ [2] (348)})$$\n",
    "\n",
    "* At logistic regression, we initialize weights 0.01 and bias 0. At this time, we initialize weights randomly. Because if we initialize parameters zero each neuron in the first hidden layer will perform the same comptation. Therefore, even after multiple iterartion of gradiet descent each neuron in the layer will be computing same things as other neurons. Therefore we initialize randomly. Also initial weights will be small. If they are very large initially, this will cause the inputs of the tanh to be very large, thus causing gradients to be close to zero. The optimization algorithm will be slow.\n",
    "* Bias can be zero initially.\n",
    "\n",
    "* Bias'ı 0 tanımlıcaz. Weight ise 0.01 tanımlanıyordu artık random şekilde tanımlıcaz.Ayrıca küçük bir sayı olması gerekir sebebi ise çeşitlillik olsun daha iyi olsun diye. Ayrıca büyük sayı seçerse tanh fonksiyonu gereği güncelleme süresi cok uzayacak, bunun için küçük değerler seçilir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec2a9ca6-e5dc-457d-8bc5-69ddc11db9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d30c86bc-9b33-4608-b1ee-f73d0a30e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize parameters and layer sizes\n",
    "def initialize_parameters_and_layer_sizes_NN(x_train, y_train):\n",
    "    parameters = {\"weight1\": np.random.randn(3,x_train.shape[0]) * 0.1, # 3,4096 , 0.1: sayıyı küçültür,  (1,4096) * (4096,3) = (1,3) ---> (3,1) +(3,1) toplayabilmek için sizeların aynısı olması lazım\n",
    "                  \"bias1\": np.zeros((3,1)),\n",
    "                  \"weight2\": np.random.randn(y_train.shape[0],3) * 0.1,\n",
    "                  \"bias2\": np.zeros((y_train.shape[0],1))} # y_train.shape[0] = 1\n",
    "    return parameters\n",
    "# sizeların matrislerle işlem yapılabilmesi için birbiri ile uyumlu olması önemlidir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c02eef-98b0-4aea-a9df-3614d476c51c",
   "metadata": {},
   "source": [
    "\n",
    "## Forward propagation\n",
    "* Forward propagation is almost same with logistic regression.\n",
    "* The only difference is we use tanh function and we make all process twice.\n",
    "* Also numpy has tanh function. So we do not need to implement it.\n",
    "* Lojistik regresyon gibidir sadece tanh kullandığımız için iki kere uyguluyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c1718fe-3529-4ca3-8471-a2a9a7990bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_propagation_NN(x_train, parameters):\n",
    "\n",
    "    Z1 = np.dot(parameters[\"weight1\"],x_train) +parameters[\"bias1\"]\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(parameters[\"weight2\"],A1) + parameters[\"bias2\"]\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache\n",
    "# daha sonra kullancağımız için return ettik. Dictionary şekilde depo etme sebebi de 4 tane ve bu değerlerin adını bildiğimizi için daha kolay oluyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf80e6a-4f0a-49ca-9166-45dc1fa4a306",
   "metadata": {},
   "source": [
    "\n",
    "## Loss function and Cost function\n",
    "* Loss and cost functions are same with logistic regression\n",
    "* Cross entropy function\n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "336848cd-cdf2-4057-9c07-cbfb07696283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cost\n",
    "def compute_cost_NN(A2, Y, parameters):\n",
    "    logprobs = np.multiply(np.log(A2),Y) # numpy ile log çağrıldı\n",
    "    cost = -np.sum(logprobs)/Y.shape[1] # normalizasyon \n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf829af9-a3b5-4a5b-8f7a-b12ea67f1c8a",
   "metadata": {},
   "source": [
    "\n",
    "## Backward propagation\n",
    "* As you know backward propagation means derivative.\n",
    "* If you want to learn (as I said I cannot explain without talking bc it is little confusing), please watch video in youtube.\n",
    "* However the logic is same, lets write code.\n",
    "* Cost functionın weightlere göre türevini bulup belirli kurallar eşliğinde güncellicez.\n",
    "* Cost'un z2'ye göre z2'nin de w1'e göre türevi cost ile z1 arasında ilişi kurdurur.\n",
    "* Yani cost'un w1'e göre türevi için ara türevi de almalısın. Zincir kuralıdır.\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cfdb398a-3325-4f13-ac5d-da41a07e3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Propagation\n",
    "def backward_propagation_NN(parameters, cache, X, Y):\n",
    "\n",
    "    dZ2 = cache[\"A2\"]-Y\n",
    "    dW2 = np.dot(dZ2,cache[\"A1\"].T)/X.shape[1] # costun z2'ye göre türevi\n",
    "    db2 = np.sum(dZ2,axis =1,keepdims=True)/X.shape[1]\n",
    "    dZ1 = np.dot(parameters[\"weight2\"].T,dZ2)*(1 - np.power(cache[\"A1\"], 2)) # power:üssü\n",
    "    dW1 = np.dot(dZ1,X.T)/X.shape[1]\n",
    "    db1 = np.sum(dZ1,axis =1,keepdims=True)/X.shape[1] # costun b1 e göre türevi , keepdims : array olarak tutar\n",
    "    grads = {\"dweight1\": dW1,\n",
    "             \"dbias1\": db1,\n",
    "             \"dweight2\": dW2,\n",
    "             \"dbias2\": db2}\n",
    "    return grads\n",
    "    # bu türevleri depoluyoruz bunlar stepler olacak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09a9c866-0e84-462a-9c0f-821266c2d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# değişimleri biliyoruz yani artık stepleri biliyoruz update edebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe80d9c-2e3a-41c7-8338-ad576d4f42ab",
   "metadata": {},
   "source": [
    "\n",
    "## Update Parameters \n",
    "* Updating parameters also same with logistic regression.\n",
    "* We actually do alot of work with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ccb88764-3e95-4b43-a189-39ac95026e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update parameters\n",
    "def update_parameters_NN(parameters, grads, learning_rate = 0.01):\n",
    "    parameters = {\"weight1\": parameters[\"weight1\"]-learning_rate*grads[\"dweight1\"],\n",
    "                  \"bias1\": parameters[\"bias1\"]-learning_rate*grads[\"dbias1\"],\n",
    "                  \"weight2\": parameters[\"weight2\"]-learning_rate*grads[\"dweight2\"],\n",
    "                  \"bias2\": parameters[\"bias2\"]-learning_rate*grads[\"dbias2\"]}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49a74c4a-9c9a-4379-90cc-b0f7d9a570d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelimiz hazır predict edebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a0d366-17be-4f9d-80ce-f230c5016b06",
   "metadata": {},
   "source": [
    "\n",
    "## Prediction with learnt parameters weight and bias\n",
    "* Lets write predict method that is like logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c55ba30e-b022-4785-b299-d282d9881433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def predict_NN(parameters,x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    A2, cache = forward_propagation_NN(x_test,parameters)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
    "    for i in range(A2.shape[1]):\n",
    "        if A2[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca3fd4-90a2-4f3d-9eb3-ba9db1ebaa3a",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "* Lets put them all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "075b6c44-4259-4edd-aa8e-4eed0304408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.360968\n",
      "Cost after iteration 100: 0.349736\n",
      "Cost after iteration 200: 0.347023\n",
      "Cost after iteration 300: 0.350868\n",
      "Cost after iteration 400: 0.341807\n",
      "Cost after iteration 500: 0.315780\n",
      "Cost after iteration 600: 0.274199\n",
      "Cost after iteration 700: 0.230731\n",
      "Cost after iteration 800: 0.334282\n",
      "Cost after iteration 900: 0.193454\n",
      "Cost after iteration 1000: 0.150714\n",
      "Cost after iteration 1100: 0.126453\n",
      "Cost after iteration 1200: 0.112574\n",
      "Cost after iteration 1300: 0.101645\n",
      "Cost after iteration 1400: 0.092664\n",
      "Cost after iteration 1500: 0.085101\n",
      "Cost after iteration 1600: 0.078506\n",
      "Cost after iteration 1700: 0.072581\n",
      "Cost after iteration 1800: 0.067218\n",
      "Cost after iteration 1900: 0.062422\n",
      "Cost after iteration 2000: 0.058192\n",
      "Cost after iteration 2100: 0.054357\n",
      "Cost after iteration 2200: 0.050635\n",
      "Cost after iteration 2300: 0.046962\n",
      "Cost after iteration 2400: 0.043828\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 99.71264367816092 %\n",
      "test accuracy: 95.16129032258064 %\n"
     ]
    }
   ],
   "source": [
    "# 2 - Layer neural network\n",
    "def two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations):\n",
    "    cost_list = []\n",
    "    index_list = [] # cost ve indexleri depolucam cünkü daha sonra görselleştirme yapıp analiz etmek için\n",
    "    #initialize parameters and layer sizes\n",
    "    parameters = initialize_parameters_and_layer_sizes_NN(x_train, y_train) # boyutları çekebilelim\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         # forward propagation\n",
    "        A2, cache = forward_propagation_NN(x_train,parameters)\n",
    "        # compute cost\n",
    "        cost = compute_cost_NN(A2, y_train, parameters)\n",
    "         # backward propagation\n",
    "        grads = backward_propagation_NN(parameters, cache, x_train, y_train)\n",
    "         # update parameters\n",
    "        parameters = update_parameters_NN(parameters, grads)\n",
    "        \n",
    "        if i % 100 == 0: # her 100 adımda bir depolucaz\n",
    "            cost_list.append(cost)\n",
    "            index_list.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    plt.plot(index_list,cost_list)\n",
    "    plt.xticks(index_list,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    \n",
    "    # predict\n",
    "    y_prediction_test = predict_NN(parameters,x_test)\n",
    "    y_prediction_train = predict_NN(parameters,x_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    return parameters\n",
    "parameters = two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19d91c2a-0c77-47e9-aca9-7de1ffc1793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problemimizi daha genel hale getirmek için keras kütüphanesi yardımıyla L Layer yapıcaz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f0793-2932-461d-a446-827304d02e99",
   "metadata": {},
   "source": [
    "<a id=\"19\"></a> <br>\n",
    "# L Layer Neural Network\n",
    "* **What happens if number of hidden layer increase:** Earlier layerls can detect simple features.\n",
    "* When model composing simple features together in later layers of neural network that it can learn more and more complex functions. For example, lets look at our sign one.\n",
    "![resim](10.jpg)\n",
    "* For example first hidden layer learns edges or basic shapes like line. When number of layer increase, layers start to learn more complex things like convex shapes or characteristic features like forefinger.\n",
    "* Lets create our model\n",
    "    * There are some hyperparameters we need to choose like learning rate, number of iterations, number of hidden layer, number of hidden units,(node sayısı) type of activation functions. Woww it is too much :)\n",
    "    * These hyperparameters can be chosen intiutively if you spend a lot of time in deep learning world.\n",
    "    * However, if you do not spend too much time, the best way is to google it but it is not necessary. You need to try hyperparameters to find best one.\n",
    "    * In this tutorial our model will have 2 hidden layer with 8 and4 nodes, respectively. Because when number of hidden layer and node increase, it takes too much time. \n",
    "    * As a activation function we will use relu(first hidden layer), relu(second hidden layer) and sigmoid(output layer) respectively.\n",
    "    * Number of iteration will be 100.\n",
    "* Our way is same with previous parts however as you learn the logic behind deep learning, we can ease our job and use keras library for deeper neural networks.\n",
    "* Hidden sayısı arttıkça daha karmaşık şeyleri öğrenir. Nonlineerlik artar , karışık şeyler öğrenilebiilir.\n",
    "* hidden layer ve node sayısı arttıkça  karmaşıklık öğrenmesi artar ancak pc ram kapasitesi hızı artmalı yoksa kasar.\n",
    "* relu fonksiyonunun türevini alması kolay ve diğerlerine göre daha hızlıdır.\n",
    "* binart class yaptığımız için output da sigmoid kullanıyoruz\n",
    "* Bu kısımdaki amacımız keras kullanarak l layer neural network nasıl yapılır , hyperparametreler nasıl ayarlanılır .\n",
    "* First lets reshape our x_train, x_test, y_train and y_test.\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ca32a54-819b-4c08-a340-334bdb12292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping\n",
    "x_train, x_test, y_train, y_test = x_train.T, x_test.T, y_train.T, y_test.T \n",
    "# Transpoze alıyoruz çünkü kerasta kullanırken  transpoze almamız gerekiyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ea86d-e38f-41cf-8e96-cb18cd03f52d",
   "metadata": {},
   "source": [
    "\n",
    "## Implementing with keras library\n",
    "Lets look at some parameters of keras library:\n",
    "* units: output dimensions of node , layerdaki node sayısı\n",
    "* kernel_initializer: to initialize weights\n",
    "* activation: activation function, we use relu\n",
    "![resim](11.jpg)\n",
    "\n",
    "* input_dim: input dimension that is number of pixels in our images (4096 px)\n",
    "* optimizer: we use adam optimizer\n",
    "    * Adam is one of the most effective optimization algorithms for training neural networks. (Adaptif momentum learning rate daha önce sabitti burda ise learning rate güncelleyerek kendini günceller)\n",
    "    * Some advantages of Adam is that relatively low memory requirements and usually works well even with little tuning of hyperparameters ( memoryi daha efektif kullanıyoruz)\n",
    "* loss: Cost function is same. By the way the name of the cost function is cross-entropy cost function that we use previous parts.\n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}$$\n",
    "* metrics: it is accuracy.\n",
    "* cross_val_score: use cross validation.\n",
    "* epochs: number of iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e5ad455-de83-4906-a50c-70043ff99b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 6ms/step - loss: 0.6933 - accuracy: 0.4397\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5302\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5431\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5431\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5431\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6926 - accuracy: 0.5431\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6924 - accuracy: 0.5431\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5431\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5431\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5431\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6920 - accuracy: 0.5431\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6919 - accuracy: 0.5431\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5431\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5431\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5431\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6891 - accuracy: 0.5474\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6810\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.5819\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.8276\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.7371\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.8319\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6078\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.7931\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6179 - accuracy: 0.6767\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6036 - accuracy: 0.7284\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5854 - accuracy: 0.8233\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7931\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.7759\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7802\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5285 - accuracy: 0.8793\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4995 - accuracy: 0.8319\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.9095\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8190\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4779 - accuracy: 0.9095\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8448\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.9052\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.8793\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.9095\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.9095\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8664\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.9095\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.9353\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.8750\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.9397\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.9052\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.9526\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.9095\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4062 - accuracy: 0.9397\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4098 - accuracy: 0.9224\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.9440\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.9181\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.9440\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.9181\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.9526\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.9483\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.9224\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.9440\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.9483\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.9526\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.9483\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3547 - accuracy: 0.9526\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3527 - accuracy: 0.9483\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.9483\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3478 - accuracy: 0.9483\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3503 - accuracy: 0.9483\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.9655\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3531 - accuracy: 0.9353\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3494 - accuracy: 0.9526\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3450 - accuracy: 0.9440\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.9612\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.9483\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.9655\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.9612\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3248 - accuracy: 0.9483\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3204 - accuracy: 0.9655\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.9440\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.9612\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.9569\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.9655\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.9569\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.9569\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.9612\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.9655\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.9569\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3000 - accuracy: 0.9569\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.9569\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.9483\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.9569\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3031 - accuracy: 0.9483\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.9698\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.9655\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.9698\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.9655\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9784\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9698\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.9784\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.9655\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9569\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5216\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5216\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5216\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6808 - accuracy: 0.5216\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.5216\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6623 - accuracy: 0.5216\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.5216\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6388 - accuracy: 0.5216\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.7716\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6681\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5648 - accuracy: 0.6552\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.8060\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7845\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8060\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8103\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.8362\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4786 - accuracy: 0.8793\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8922\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4279 - accuracy: 0.8707\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.9181\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8966\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.9483\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.9181\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.9569\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.9224\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.9009\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.9224\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.9353\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.9224\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.9353\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.9095\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.9181\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.9397\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.9569\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.9698\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3128 - accuracy: 0.9526\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.9612\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.9784\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.9569\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2915 - accuracy: 0.9569\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.9698\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.9612\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.9526\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.9741\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.9569\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.9569\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2671 - accuracy: 0.9741\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.9655\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2615 - accuracy: 0.9741\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.9741\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2508 - accuracy: 0.9698\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9741\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2284 - accuracy: 0.9655\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9741\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9698\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9698\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9655\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9871\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9828\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1969 - accuracy: 0.9914\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9871\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9828\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2028 - accuracy: 0.9698\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1899 - accuracy: 0.9741\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9957\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9741\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9871\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1677 - accuracy: 0.9914\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1790 - accuracy: 0.9828\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1612 - accuracy: 0.9871\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9698\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.9267\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.9784\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9914\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9914\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9914\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9957\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9957\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.9871\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9914\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1280 - accuracy: 0.9957\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9914\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1261 - accuracy: 0.9957\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9957\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9957\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9871\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1284 - accuracy: 0.9914\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9828\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9957\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9957\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9957\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 1.0000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.9483\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4957\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5388\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.4957\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.4957\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.4957\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5733\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.4957\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.6810\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.5345\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.5776\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6250\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.7457\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.5819\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6552\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.8578\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6336\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5583 - accuracy: 0.8103\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7802\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.8448\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8319\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8190\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8707\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4662 - accuracy: 0.8491\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8448\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.9009\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4328 - accuracy: 0.8793\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4268 - accuracy: 0.9267\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.4142 - accuracy: 0.9052\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4057 - accuracy: 0.9181\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.9224\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.9095\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.9181\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4025 - accuracy: 0.9440\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.9138\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.9440\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3620 - accuracy: 0.9655\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3833 - accuracy: 0.9138\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.9224\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3513 - accuracy: 0.9698\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.9483\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.9483\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3385 - accuracy: 0.9655\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3319 - accuracy: 0.9612\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.9655\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3239 - accuracy: 0.9569\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3204 - accuracy: 0.9569\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.9569\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.9741\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.9612\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.9655\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.9569\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.9828\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.9655\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3126 - accuracy: 0.9828\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.9353\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.9655\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.9828\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2871 - accuracy: 0.9741\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2852 - accuracy: 0.9698\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2874 - accuracy: 0.9741\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.9655\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.9741\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.9828\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.9698\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.9828\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.9784\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.9871\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9784\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9698\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.9828\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.9698\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.9871\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9569\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.9784\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.9655\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.9655\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.9871\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9871\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.9828\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.9655\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.9655\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2553 - accuracy: 0.9612\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9828\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.9828\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2412 - accuracy: 0.9784\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.9871\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2436 - accuracy: 0.9655\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9871\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9828\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9871\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2302 - accuracy: 0.9871\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9871\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9871\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9871\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2304 - accuracy: 0.9828\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2243 - accuracy: 0.9828\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.9871\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.9138\n",
      "Accuracy mean: 0.9396551648775736\n",
      "Accuracy variance: 0.018622823490333857\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier #classiferımız \n",
    "from sklearn.model_selection import cross_val_score # 5 olunca 4 train 1 val boluyordu. 5 kere yapıordu . accuracylerın ortalamasın alıyordu\n",
    "from keras.models import Sequential # initialize neural network library , weight ve bias initalize edicez\n",
    "from keras.layers import Dense # build our layers library , layerları build etmek için kullandığımız metot olucak\n",
    "\n",
    "# yapıyı hazılıyoruz\n",
    "def build_classifier(): # neural networkumu oluşturacak yapı olacak \n",
    "    classifier = Sequential() # initialize neural network , bir yapı oluşturduk , bu yapıya layerları eklemek lazım. bu yapıp inşaa etmek için dense kullanıcaz.\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1])) # kernel_initialize : weightlerin initilizae edilme yöntemi, 2 layer networks de de aynısnı yapmıştık. x_train_shape[1] yazmak zorundayız yoksa hata alırız . 4096 olucak\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) # classiferı compile etmek için optimizasyon parametrelerini tanıtıyorum. Back yapmak için 'adam' kullanıyoruz. Eskiden lr sabit tutarak gradient descent yapıyorduk. Adam'da lr güncellenir.  Değerlendirme yapılacak metrik : accuracy\n",
    "    return classifier\n",
    "\n",
    "# sınıflandırıcı  kullanıyoruz\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n",
    "# eğitip accruacy elde ediyoruz\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3) # birden fazla accuracy veriyor ve meanini alarak işlem yapıyor. cv=3 vererek 3 kez accuracy bulacak\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "# bu şekilde keras kullanarak neural network inşaa ettik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57431998-3d19-4cc0-a109-6dc479ef30e8",
   "metadata": {},
   "source": [
    "\n",
    "## Artificial Neural Network with Pytorch library.\n",
    "* Pytorch is one of the frame works like keras.\n",
    "* It eases implementing and constructing deep learning blocks.  \n",
    "* Artificial Neural Network: https://www.kaggle.com/kanncaa1/pytorch-tutorial-for-deep-learning-lovers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b5544-17f9-473f-afe8-85358845ad74",
   "metadata": {},
   "source": [
    "\n",
    "## Convolutional Neural Network with Pytorch library.\n",
    "* Pytorch is one of the frame works like keras.\n",
    "* It eases implementing and constructing deep learning blocks.  \n",
    "* Convolutional Neural Network: https://www.kaggle.com/kanncaa1/pytorch-tutorial-for-deep-learning-lovers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad3681e-dd3c-4cd7-8cae-03cc92f27c77",
   "metadata": {},
   "source": [
    "\n",
    "## Recurrent Neural Network with Pytorch library.\n",
    "* Pytorch is one of the frame works like keras.\n",
    "* It eases implementing and constructing deep learning blocks.  \n",
    "* Recurrent Neural Network: https://www.kaggle.com/kanncaa1/recurrent-neural-network-with-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748efe10-3670-4116-ab1b-e53f9730541f",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.87149&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a35e7-e09d-45ba-86bf-abd26131d0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv]",
   "language": "python",
   "name": "conda-env-.conda-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
